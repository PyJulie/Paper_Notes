## 笔记作者的话
理解本篇文章，首先要对两种不确定性有深刻的理解
### 随机不确定性 
* [原文链接](https://blog.csdn.net/chichuhe/article/details/83047507)
* 随机不确定性：此种不确定性主要由自然变异和随机性引起。随机不确定性的例子包括风速、风向、降雨量、产品质量的变化、污染物在食品中的浓度等。
* 例子１：考虑一个化工厂毒气泄露的事故场景，有毒气体泄露后形成毒气云其最终影响取决于实时的风向。通过对相关地点风向的长期观察，我们可以拟合出不同方向d的概率分布。在事故场景发生的时候，我们无法确定毒气云一定会吹向居民区，但是我们可以使用分布F（d）寻找事件的概率。
* 认知不确定性
* 此种不确定性主要是由于缺乏知识引起。常见的例子包括转基因食品的健康风险以及二氧化碳排放导致全球变暖的担忧。从原理上讲，如果我们获得了有关研究对象足够的知识，就可以消除这种不确定性。鉴于随着知识增加，认知不确定性可以因此降低，所以它也可以被称为可降低的不确定性。与随机不确定性相反，认知不确定性依赖于评估者的知识水平，因此它还被称为主观不确定性。
* 认知不确定性也被称为无知（ignorance）（Salvatore Modica,1997）和表象不确定性。
* 无知可以分为两种：认识到的无知和没有认识到的无知。认识到的无知是指，我们知道自己不知道，并希望在进行风险分析的时候采取相应措施。而没有认识到的无知则更加危险，因为我们根本不知道自己不知道，说的更严重点，就是我们对于风险评估结果的信心可能就是一种错觉。
* 例子２：现在，有很多基于纳米技术的新产品不断问世。然而许多人都在担心纳米颗粒会对他们的健康以及地球环境造成伤害。但是至少到现在（2014年），纳米技术的影响还无从所知，因此与使用这项技术相关的认知不确定性还非常高。随着人们关于纳米技术的经验越来越多，认知不确定性也就会随之降低。

### 为什么要关心不确定性？
* [原文链接](http://wemedia.ifeng.com/72003766/wemedia.shtml)
* 比较典型的例子是高风险应用。假设你正在建立一个模型，帮助医生决定患者的首选治疗方案。在这种情况下，我们不仅要关心模型的准确性，还要关注模型对预测的确定程度。如果不确定性太高，医生应该将此考虑在内。
* 自驾车也是一个例子。当模型不确定道路上是否有行人时，我们可以使用此信息来减慢车速或触发警报，以使驾驶员接手。
* 不确定性也可以帮助我们摆脱数据实例。如果模型没有使用类似于手边样本的实例进行训练，那么如果它能够说“抱歉，我不知道”可能会更好。这可以避免谷歌在将非洲裔美国人误认为大猩猩时这样的尴尬错误。这种错误有时是由于训练集不够多样化产生的。
* 最后一次使用不确定性（也是本文的目标），是从业者调试模型的工具。我们稍后会深入研究这个问题，但首先，让我们谈谈不同类型的不确定性。
* ![figure1](images/what_uncer/figure1.jpg)
* 左侧：没有足够的数据导致高度不确定性。右边：给定更多数据不确定性降低
* ![figure2](images/what_uncer/figure2.jpg)
* 举个例子，假设你想要建立一个能够获得动物图片的模型，并预测该动物是否会尝试吃掉你。假设你用狮子和长颈鹿的图片训练模型，现在它看到了一个僵尸。由于该模型没有在僵尸图片上进行过训练，因此不确定性很高。这种不确定性就是模型的结果，如果给出僵尸图片够多，不确定性就会减少。

## 摘要
* 主要有两种不确定性，偶然不确定性（aleatoric uncertainty）捕获观测中固有的噪声，认知不确定性（epistemic uncertainty）用来描述模型中的不确定性，这种不确定性可以在有充足的数据量的情况下得到合理解释。
* 使用贝叶斯深度学习工具可以帮助理解计算机视觉中的不确定性。
* 提出了一个贝叶斯深度学习框架，研究了像素级的语义分割和深度回归任务。
* 同时，基于所提出的不确定性公式，本文针对以上问题设计了新的损失函数，这使得衰减项对噪声具有更高的鲁棒性，同时得到目前性能最好的语义分割和深度回归结果。

## 介绍
* 很多机器学习算法可以很好地将高维空间的数据映射成低维数组，但很少考虑这些映射的准确率，从而导致很多灾难性的后果。
量化不确定性在计算机视觉领域可以被分为回归和分类两大类。现存的描述不确定性的方法有粒子滤波法，条件随机场法。深度学习方法往往很难描述不确定性。例如在分类问题中，深度学习算法常常更够给出归一化的得分向量，但是不需要计算模型的不确定性。基于贝叶斯的深度学习算法则可以在拥有深度学习高性能的同时计算出模型的不确定性。
* 同方差不确定性（homoscedastic）和异方差不确定性（heteroscedastic）。偶然不确定性是同方差不确定性，是模型固有不确定性；认知不确定性是异方差不确定性，是由于每个输入的噪声不同造成的。
* 在大数据背景下对偶然不确定性进行建模是十分重要的，偶然不确定性往往是不能通过大量数据进行解释的，因此本文提出一种统一的贝叶斯深度学习框架对偶然不确定性进行映射并将其与认知不确定性相结合，本文所提出的框架可同时在分类和回归问题中进行使用。
### 创新点：
* 我们掌握了对偶然和认知不确定性的精确的描述方法，特别的，我们提出了一种新的基于不确定性的 分类方法。
* 通过明确表示出偶然不确定性而获得的隐含衰减（the implied attenuation）减少了噪声的影响，基于此，我们提出的模型可以提高非贝叶斯模型性能的1-3%。
* 本文通过表征两种不确定性的特性以及比较两种模型的性能和计算时间来研究如何对两者进行权衡。
