# Realistic Evaluation of Deep Semi-Supervised Learning Algorithms

## 摘要
* SSL在数据标签有限时可以起到巨大的作用
* 一些benchmark上的成功并不代表在实际问题中也能有效
* 作者做了一些目前广泛应用的SSL方法是实现，发现存在underreported
* 无label数据和有label的数据如果不在同一个分布，性能会显著下降
* 为了研究SSL的真实可用性，作者设计了一套评估方法

## introduction
* 很多SSL方法都证明了如果数据存在大量无label的情况，SSL也能够接近监督学习的表现
* 这种成功在cifar等数据集上都得到了验证，但无法确定是否适用于真实场景
* 作者试图提出一个新的问题来直接回答以上的问题
* 作者发现：
    * 当使用的超参数相同时，半监督学习和监督学习的差距会较小
    * 精心选择正则项，大分类器在具有少量标注的数据集上也有很好的效果，这说明在同一底层模型上评估不同的SSL方法的重要性
    * 在不同的带标记的数据集上预训练分类器，然后对目标数据集中的标记数据重新训练，效果超出了所有的SSL算法
    * 当未标注的数据集和带标注的数据集不在同一分布时，效果会急剧下降
    * 标注方法，两部分数据的比例，对敏感性都有影响
    * 数据集太小，得到的比较结果通常是不太可靠的
* 作者提出了一套新的评估技术
* s2提出了较现有方法的改进方式
* s3讨论了用于deep architecture的现代SSL方法，强调了在我们研究中的部分
* s4大量的实验，验证我们方法的有效性，作者只测试了cv领域，因为很通用
* s5总结了SSL技术的一些具体建议

## 改进
* A Shared implementation 在对训练后的网络作比较时，网络结构一样，但也要注意一些训练细节也要保持相似，包括参数初始化，数据预处理，学习率等，这些差异的不同会导致我们比较的结果是不可靠的，这个问题并非是SSL中独有的问题，在机器学习中普遍存在
* baseline应当是最佳的，也就是说，如果你要保证SSL效果会超过监督学习，那么你首先在监督学习上建立的baseline应当是最好的效果，作者花了1000次超参数优化实验来做这个调整
* 对迁移学习的比较，虽然迁移学习仅适用于source和target相似的场景，但还是有做比较的价值
* 作者研究了不同分布的数据集的影响
* 调整两种数据集的比例
* 分析了验证集与训练集的比例问题，实际上我们更期望于更多的数据用于训练，因为验证集太少会无法测试性能，做交叉训练成本又太高

## 半监督学习方法
* SSL的目的是用未标注的数据的信息去增强我们的模型
